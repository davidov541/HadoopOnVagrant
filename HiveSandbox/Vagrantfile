# -*- mode: ruby -*-
# vi: set ft=ruby :

# All Vagrant configuration is done below. The "2" in Vagrant.configure
# configures the configuration version (we support older styles for
# backwards compatibility). Please don't change it unless you know what
# you're doing.
Vagrant.configure("2") do |config|
    config.vm.define "hivesandbox" do |node|
        node.vm.box = "centos/7"
        node.vm.provider "virtualbox" do |vb|
            vb.memory = "1024"
        end
        node.vm.hostname = "hivesandbox"
        node.disksize.size = "50GB"
        node.vm.synced_folder "Shared", "/vagrant_shared"
        node.vm.synced_folder "../common", "/vagrant_common"
        node.vm.network "public_network"
        node.vm.network "private_network", ip: "10.0.0.51", virtualbox__intnet: true
        node.vm.provision :shell, inline: <<-SHELL
        sudo su
        cd /root

        yum -y install https://centos7.iuscommunity.org/ius-release.rpm
        yum -y install epel-release python36u python36u-dev npm wget net-tools git protobuf-compiler patch
        yum -y install python36u-pip java-1.8.0-openjdk screen

        ln -s /bin/pip3.6 /bin/pip
        python3 -m pip install --upgrade pip
        python3 -m pip install shyaml

        chmod +x /vagrant_*/*.sh

        mkdir /grid
        pushd /grid
        wget -q http://mirrors.ocf.berkeley.edu/apache/hadoop/common/hadoop-3.2.1/hadoop-3.2.1.tar.gz
        tar zxf hadoop-3.2.1.tar.gz
        ln -s hadoop-3.2.1*/ hadoop

        if [ -f /vagrant_shared/hive.tar.gz ]; then
            \\cp /vagrant_shared/hive.tar.gz .
        else
            wget -q http://apache.cs.utah.edu/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz
            mv apache-hive-3.1.2-bin.tar.gz hive.tar.gz
        fi
        \\cp /vagrant_shared/hive.tar.gz .
        tar zxf hive.tar.gz
        ln -s apache-hive-*/ hive
        popd

        groupadd hadoop
        groupadd hive
        useradd -g hadoop --shell=/bin/bash -m -d /home/hive hive
        useradd -g hadoop --shell=/bin/bash -m -d /home/hdfs hdfs

        mkdir /root/hdfs-scratch
        mkdir -p /home/hive/warehouse
        mkdir /tmp/hive
        chmod 777 /tmp/hive

        \\cp /vagrant_shared/runHive.sh /root/
        chmod 744 /home/hive/runHive.sh

        chown -R hive /home/hive/
        chgrp -R hive /home/hive/

        chown -R hive /grid/hive
        chown -R hdfs /grid/hadoop
        chgrp -R hadoop /grid
        chmod -R 775 /grid

        echo -e "export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/jre\n" >> /etc/bashrc
        echo -e "export HADOOP_HOME=/grid/hadoop\n" >> /etc/bashrc
        echo -e "export HIVE_HOME=/grid/hive\n" >> /etc/bashrc
        echo -e "export PATH=/grid/hadoop/bin:/grid/hive/bin:$PATH\n" >> /etc/bashrc

        /vagrant_common/setupPasswordlessSSH.sh
        su -c "/vagrant_common/setupPasswordlessSSH.sh" - hdfs
        su -c "/vagrant_common/setupPasswordlessSSH.sh" - hive

        su -c "/grid/hadoop/bin/hdfs namenode -format" - hdfs

        rm -f /grid/hive/lib/guava-19.0.jar
        cp -f /grid/hadoop/share/hadoop/common/lib/guava-27.0-jre.jar /grid/hive/lib/

        \\cp -f /vagrant_shared/core-site.xml /grid/hadoop/etc/hadoop/
        \\cp -f /vagrant_shared/hive-site.xml /grid/hive/conf/

        su -c "/grid/hadoop/sbin/start-dfs.sh" - hdfs
        su -c "$HADOOP_HOME/bin/hadoop fs -mkdir /tmp" - hdfs
        su -c "$HADOOP_HOME/bin/hadoop fs -mkdir -p /user/hive/warehouse" - hdfs
        su -c "$HADOOP_HOME/bin/hadoop fs -chgrp -R hadoop /tmp" - hdfs
        su -c "$HADOOP_HOME/bin/hadoop fs -chgrp -R hadoop /user" - hdfs
        su -c "$HADOOP_HOME/bin/hadoop fs -chown -R hive /user/hive" - hdfs
        su -c "$HADOOP_HOME/bin/hadoop fs -chmod g+w /tmp" - hdfs
        su -c "$HADOOP_HOME/bin/hadoop fs -chmod g+w /user/hive/warehouse" - hdfs
        SHELL
    end
end